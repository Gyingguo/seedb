\section{System architecure}

\subsection{\SeeDB overiew}
\label{overview}

Figure \ref{XXX} shows the architecture of our system. Currently, \SeeDB\ is a
wrapper around a database (PostgreSQL in this case). While optimization
opportunities are restricted by virtue of being outside the DBMS, we believe
that it allows quick iteration and permits \SeeDB\ to be used with different
backends. 

Once a user issues a query $Q$ to \SeeDB\, the system generates potential views
by rewriting $Q$ with various group-bys and aggregates. Each such rewritten
query is termed as a ``view.'' These views are then grouped according to
optimization opportunities discussed in \ref{optimizations} and sent to the
DBMS. The results of these view queries are then processed by \SeeDB to compute
the utility of views. The top-k views with highest utility are picked,
appropriate visualization techniques chosen and the top views are visualized at
the \SeeDB front end. The analyst can then examine these views and perform
further processing.

\subsection{Basic Framework}
\label{basic_framework}

Given a user query $Q$, the basic version of \SeeDB\ computes all possible view
queries by adding a single aggregate and group-by operator. Each of these view
queries is executed at the backend along with an equivalent aggregate+group-by
query on the complete underlying dataset. These two query results produce a
``distribution'' for the attribute that has been aggregated. These two
distributions are compared using the chosen distance metric (default: earth
movers distance, other: L2, Jensen-Shannon distance etc). All the views are
ranked by the distance between the query and dataset distribution and the
top k views with the largest distance are chosen. Appropriate visualizations are
chosen for these distributions (heuristics in Section \ref{user_interface}) and
are displayed to the user for further interaction.

{\bf Utility Metric}:

One of the key challenges behind \SeeDB\ 
is formalizing the utility function $U(R)$ for a discriminating view $R$. 
There are many choices for $U$ and we expect \SeeDB\ 
to recommend views that score high on several metrics. 
As discussed previously, the proposed metric tries to capture the idea of
``deviation'' between distributions, i.e., a view has high utility if its
contents show a trend that deviates from the corresponding trend in the original
database.

We first define some notation. For any discriminating view $R_i$ 
in the class defined above, we note that $R_i(D)$ and $R_i(Q(D))$ 
are both two column tables. 
A two-column table can be represented using a weight vector.
We let the weight vector $W_{a, f(m)}$ represent the 
result of $R_i(D) = \gamma_{a, f(m)}(D)$, i.e., 
distribution of the aggregate function $f$ on the measure quantity $m$ 
across various values of the attribute $a$. 

The utility $U$ of a discriminating view $\gamma_{a, f(m)}$ is defined to be the
distance between $W_{a, f(m)}^Q$, and $W_{a, f(m)}$:
$U(\gamma_{a, f(m)}) = S(W_{a, f(m)}^Q, $ $W_{a, f(m)})$ where $S$ is a distance
metric. The higher $S$ is, the more useful a discriminating view is.
Common distance metrics used in visualization literature include K-L
divergence~\cite{wikipedia-KL}, Jenson-Shannon
distance~\cite{wikipedia-JS,entropy-vis}, and earth mover
distance~\cite{wikipedia-prob-dist}.
Wang~\cite{entropy-vis} provides a good overview of the metrics used in
scientific visualizations, while \cite{wikipedia-prob-dist} provides a summary
of probability-based distance metrics.
As discussed earlier, we do not prescribe any specific distance metrics,
instead, we plan to support a whole range of distance metrics, which can be
overridden by the data analyst.

\subsection{Optimizations}
\label{optimizations}

The fact that \SeeDB\ evaluates a large number of possible views presents
various opportunities for optimization. The strategies include:

\begin{enumerate}
  \item {\it Rewrite view query}: Since similar group-by and aggregate queries
  are executes on the results of user query $Q$ and the underlying dataset, we
  can combine these queries into one query. As shown in Figure \ref{}.a this
  achieves a speed-up of Y\%.
  \item {\it Single Group-by Multiple Aggregates}: A large number of view
  queries have the same group-by clause but aggregates on different attributes.
  A straightforward optimization combines all view queries with the same
  group-by clause into a single view query. This rewriting provides a speed up
  linear in the number of aggregate attributes. (Figure \ref{}. b).
  \item {\it Multiple Aggregate Computation}: Similar to data cubes,
  \SeeDB\ seeks to compute group-bys for a large set of attributes. One
  optimization is to combine queries with different group-by attributes into a
  single query with mulitple group-bys. For instance, consider view queries
  $VQ(Q, A_1, GB_1)$, $VQ(Q, A_1, GB_2)$ \ldots $VQ(Q, A_1, GB_n)$. Instead of
  executing them individually, we can rewrite them into a single view query
  $VQ(Q, A_1, (GB_1, GB_2\ldots GB_n))$. While this strategy reduces query
  execution time, \SeeDB\ must spend more time combining the results and
  obtaining separate aggregates for individual $GB_i$'s. This is reminiscent of
  data cube algorithms. As shown in Figure \ref{}.c the speed up depends closely
  on the number of distinct values for each of the group-by attributes and the
  memory constraints of the DBMS.
  \item {\it Sampling}: The final optimization we study for the purpose of this
  demo is sampling. Instead of running queries on the entire dataset, we
  run queries on subsets of the data at the expense of reduced accuracy.
  Figure \ref{}.d shows the effects of this optimization. << write about
  accuracy >>
  
  Although other optimizations are possible, particularly related to
  pre-computing aggregate results, we discuss them in the full paper currently
  in preparation.
\end{enumerate}

\subsection{User Interface}
\label{user_interface}

<< write about user interface, add pictures>>
