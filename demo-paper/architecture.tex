\section{System Objectives}

We now state the goals of \SeeDB\ more formally, 
to provide a blueprint for the system design sections that follow. 
When doing so, we deliberately focus on a simple setting to ground our discussion.
However, the setting we consider is an important use-case that occurs often
in practice, and was the focus of our illustrative example. 
We will consider advanced variants in Section~\ref{sec:extensions}.

\stitle{Concrete Goals:} We consider a database $D$ with a snowflake schema,
with dimension attributes $A$, measure attributes $M$, and potential aggregate
functions $F$ over the measure attributes.
We limit the class $\calQ$, of queries posed over $D$,  
to be those that select a horizontal fragment of the fact table. 
The selection of the fragment can be done with selection predicates
on the fact table, or on dimension tables through key/foreign-key joins. 
Intuitively, the idea is that the analyst specifies their interest 
in examining facts that satisfy specific conditions. 
\SeeDB\ will identify visualizations 
that show some interesting properties of these facts.

Given a query $Q$ in $\calQ$, we define $\calR_Q$,
the set of all discriminating views, to be
the set of views that perform a group-by and some aggregation 
over the results of $Q$. 
For simplicity, we assume that a discriminating view 
$R$ in $\calR_Q$ performs a group-by on a single attribute $a \in A$, 
and applies an aggregation function $f \in F$ 
on a single measure attribute $m \in M$. 
A view in this class corresponds to a two-column table 
that shows how the value of $f(m)$ varies with values of attribute $a$. 
This table can be directly visualized using a histogram, 
a bar chart or a line plot. (We consider generalizations in Section 4.)

We also assume the existence of a function $U(R)$ that can characterize the utility of each view $R(Q)$ in $\calR_Q$ (higher is better). For now, we focus on picking discriminating views that optimize $U(R)$ with latency as low as possible: we return to more general objectives in Section~\ref{sec:extensions}. Thus, our concrete goal is:
\vspace{-1pt}
\begin{goal}
\vspace{-3pt}
Given $Q \in \calQ$ and a positive integer $K$, find $K$ discriminating views $R_i \in \calR_Q$, such that the $R_i$ have the largest values of $U(R_i)$ among those in $\calR_Q$, and the total latency is minimized.
\vspace{-3pt}
\end{goal}
\vspace{-2pt}
\stitle{Operationalizing Utility:}
One of the key challenges behind \SeeDB\ 
is formalizing the utility function $U(R)$ for a discriminating view $R$. 
There are many choices for $U$ and we expect \SeeDB\ 
to recommend views that score high on several metrics. 
As discussed previously, the proposed metric tries to capture the idea of ``deviation'' between distributions, i.e., a view has high utility if its contents show a trend that deviates from the corresponding trend in the original database.  

We first define some notation. For any discriminating view $R_i$ 
in the class defined above, we note that $R_i(D)$ and $R_i(Q(D))$ 
are both two column tables. 
A two-column table can be represented using a weight vector.
We let the weight vector $W_{a, f(m)}$ represent the 
result of $R_i(D) = \gamma_{a, f(m)}(D)$, i.e., 
distribution of the aggregate function $f$ on the measure quantity $m$ 
across various values of the attribute $a$. Going back to our example, it follows that 
\vspace{-4pt}
\[
\vspace{-3pt}
W_{\att{Year, sum(Sales)}} = (2009: 100, 2010: 200, 2011: 500, 2012: 800)
\vspace{-2pt}
\]
\noindent Here $m$ is \att{Sales}, $f$ is the sum, and $a$ is the \att{Year} attribute. 
Then, we let $W_{a, f(m)}^Q$ represent the (changed) distribution of $R_i(Q(D))$, 
the aggregated quantity $m$ across values of the attribute $a$, 
when restricted to the result of the query $Q$. Thus,
\vspace{-5pt}
\[
\vspace{-3pt}
W_{\att{Year, sum(Sales)}}^{\sigma_{\att{Prod = `Staplers'}}} 
= (2009: 50, 2010: 40, 2011: 60, 2012: 50)
\vspace{-2pt}
\]

\noindent 
The utility $U$ of a discriminating view $\gamma_{a, f(m)}$ 
is defined to be the distance between $W_{a, f(m)}^Q$, and $W_{a, f(m)}$:
$U(\gamma_{a, f(m)}) = S(W_{a, f(m)}^Q, $ $W_{a, f(m)})$
where $S$ is a distance metric. 
The higher $S$ is, the more useful a discriminating view is. 
Common distance metrics used in visualization 
literature include K-L divergence~\cite{wikipedia-KL}, 
Jenson-Shannon distance~\cite{wikipedia-JS,entropy-vis}, 
and earth mover distance~\cite{wikipedia-prob-dist}. 
Wang~\cite{entropy-vis} provides a good overview 
of the metrics used in scientific visualizations, 
while \cite{wikipedia-prob-dist} provides a summary 
of probability-based distance metrics. 
As discussed earlier, we do not prescribe 
any specific distance metrics, 
instead, we plan to support a whole range of distance metrics, 
which can be overridden by the data analyst. 


\papertext{We show in our extended paper~\cite{tr} that in our example, we get the right discriminating view (i.e., that of \att{Year}) when we consider the metrics mentioned above: the utility for \att{Year} is significantly higher than that for \att{Location} for each of the metrics considered.}

\techreport{We now show for a couple of distance metrics, we get the right discriminating view (i.e., that of \att{Year}). The metric that is perhaps the easiest to explain is Earth Mover's Distance (EMD), used in many graphics visualization applications. Simply put, the metric measures how much probability ``earth'' would be necessary to transform one probability distribution into another. In our example, our normalized weight vectors for \att{Year} are (ignoring the \att{Year} field): $(0.06, $ $0.13,$ $0.31, $ $0.50)$ and $(0.25, 0.20,$ $ 0.30, 0.25)$. Here, the amount of ``earth'' that needs to be moved (and therefore $S$) is around 0.26. For \att{Location}, the normalized weight vectors are $(0.19, 0.19, 0.19, 0.43)$ and $(0.15,$ $0.2, 0.2, 0.45)$. Here, the amount of earth that needs to be moved is around $0.03$. Thus, \att{Year}, is a much more informative attribute to visualize.

We can also consider the Jenson-Shannon distance (a normalized version of the well-known Kullback-Liebler distance~\cite{wikipedia-KL}), used in many visualization applications, defined formally as (where $W_1, W_2$ are two normalized weight vectors): $$S(W_0, W_1) = H((W_0 + W_1)/2) - H(W_0)/2 - H(W_1)/2.$$ For \att{Year}, we have: $1.31 - (1.13/2 + 1.376/2) = 0.057$. For \att{Location}, we have: $1.300 - (1.309/2 + 1.287/2) = 0.002$. Thus, once again, \att{Year} is a much more informative attribute to visualize.}

\vspace{-5pt}
\section{Initial Design}
Our initial design for \SeeDB\ is as a simple wrapper over an existing database system. One straightforward workflow is as follows:
\begin{denselist}
\item {\em Step 1:} Enumerate all discriminating views $R \in \calR_Q$ and evaluate utility $U(R)$ (i.e., compute $W_{a, f(m)}^Q$ and $W_{a, f(m)}$) by issuing the corresponding counting queries to the DBMS. Select the $K$ views with highest $U(R)$. 
\item {\em Step 2:} Compute the results of these $K$ views using the DBMS, then forward the results to the visual engine.
\end{denselist}

\noindent 
It is clear that this workflow suffers from several inefficiencies. We now discuss potential optimizations, some of which require new query processing schemes specialized for the problem at hand.


\stitle{Approximate Utility Computation:} 
We can speed up Step 1 by computing the utilities of discriminating views approximately. Naturally, we would want the approximations to be accurate enough to select a good set of views for Step 2.
\techreport{In any case, \SeeDB\ should avoid selecting useless views in the output.} 

Sampling is one possible approximation method: We construct a sample of the query result $Q(D)$, 
and the underlying data $D$, and use these samples to compute approximate weight vectors $W_{a, f(m)}^Q$ and $W_{a, f(m)}$. (In fact, the latter, which does not depend on $Q$, can be computed before any queries are issued.) The question of how large a sample of $Q$ is necessary to enable the weight vectors $W_{a, f(m)}^Q$, for all $a, f, m$, to have high accuracy is, to the best of our knowledge, still open. Techniques from sampling for aggregation~\cite{DBLP:conf/vldb/Gibbons01}, and more generally, approximate query processing~\cite{wavelets, count-min-sketches} may be relevant here.

Ideally, we would want error bounds on the resulting approximate utilities, in order to enable \SeeDB\ to select views of provably high utility and avoid views of provably low utility. These guarantees may depend on the specific metric used. For instance, approximation guarantees on the magnitudes of the weight vectors may directly translate to guarantees on the earth mover distance (a simpler metric), but not the Jenson-Shannon distance (a complex metric).

\stitle{Searching the Space of Discriminating Views:} 
The space of discriminating views may be too large to search exhaustively in an efficient manner, particularly if \SeeDB\ relies on exact utility computation. Instead, it may be possible to prune the search space by leveraging relationships between discriminating views in terms of utility. For instance, functional dependencies among grouping attributes can help us infer that certain views will have the exact same utility by virtue of having the same groups. Furthermore, the search strategy that navigates the space of views may also take into account inter-dependencies: for instance,  investing computational resources to determine that a view has provably low utility would be useful, if this determination will lead to the pruning of several other views correlated with the specific view. 

%A related issue concerns the search strategy to navigate and prune the space of views. The strategy may take into account the specifics of the pruning rules mentioned above. For instance, it would be beneficial to invest computational resources in determining that a view has provably low utility if this will lead to the pruning of several other views whose utilities are correlated with the specific view. The search strategy can also leverage approximate utility computations in order to guide its choices. 

\stitle{Multi-Query Optimization:} 
Step 2 comprises the evaluation of $K$ queries and so raises opportunities for multi-query optimization~\cite{DBLP:journals/tods/Sellis88}. For instance, if we are recommending several discriminating views with the same group-by attribute, we may combine the computation of the views into a single group-by query with multiple aggregations (one per view). We expect that the opportunities to share computation will increase with more complex queries and views.   

Multi-query optimization may also be used to optimize utility computation (Step 1). For instance, multi-query optimization may reveal that $W_{a, f_i(m)}^Q$ may be computed together for all $i$. Additionally, since we make repeated calls to evaluate $W_{a, f(m)}^Q$ for different $a, f, m$, we can instead first materialize the query result $Q(D)$ and then compute the weight vectors $W_{a, f(m)}^Q$ by issuing queries on the materialized result. Materializing $Q(D)$ can also help in evaluating $R(Q(D))$ for each selected discriminating view $R$ in Step 2.

\stitle{Fusing the Two Steps:}
Up to this point we considered view selection and view computation as two separate stages inside \SeeDB. Alternatively, we may fuse the two stages in order to share work between the computation of utilities (Step 1) and the evaluation of view queries (Step 2), thus reducing end-to-end latency. 

Computing $U(R)$ requires knowledge about the contents of $R$, and therefore, we compute $U(R)$ and $R(Q(D))$ together. Since it may be prohibitively expensive to compute these quantities for each $R$, and since the end goal is to recommend only $K$ views, we may employ approximate utility computation coupled with a pruning rule. Specifically, suppose that is it possible to schedule the computation of $Q(D)$ and receive its output in a random order (e.g., as described in~\cite{dbo}). \SeeDB\ will then observe a sample of increasing size as it consumes the output of $Q(D)$. Processing the output involves two tasks: (a) updating a running estimate of the utility of each view (leveraging the fact that the observed output is a sample of $Q(D)$), and (b) updating the current contents of unpruned views using hash-based aggregation. \SeeDB\ can use the running utility estimates to prune views of low utility. Overall, as \SeeDB\ processes $Q(D)$ it can make progress towards both selecting the top-$K$ views and computing their contents. Thus, this specialized query-processing strategy can reduce \SeeDB's end-to-end latency but it comes with higher resource requirements (since many group-by queries need to be processed concurrently).


\techreport{However, processing many queries concurrently is essentially the same as multi-query optimization and so we expect it to have a similar resource footprint. Moreover, it is possible to partition the set of views and apply this strategy to select the top-$K$ views in each part, and subsequently select the final top-$K$ views in a post-processing step. Each part will involve fewer views and hence require fewer resources, but the total work to select the top-$K$ views will be higher. }

\eat{
\stitle{Statistics and Adaptation:} 
Even for a single input query $Q$, \SeeDB\ typically computes the results of many SQL queries using the DBMS --- both for computing utility of discriminating vies, and for computing the results of the selected discriminating views. It may be advantageous to compute the results of some queries in advance, in order to obtain better or more accurate distribution statistics on $D$, so that the remaining queries to the DBMS can benefit from better optimization based on accurate statistics.

For instance, the \SeeDB\ optimizer can choose to compute $Q(D)$ first, followed by estimating statistics, which may then be used to more efficiently compute the results of the discriminating views.Overall, there is an interesting space of possibilities that may also benefit from prior work on adaptive query optimization for conventional queries~\cite{DBLP:journals/ftdb/DeshpandeIR07}.
}

% The \SeeDB\ optimizer has three alternatives to choose from for 
% a given discriminating view $R_i(Q)$:
% First, it can chose to optimize and execute first the part 
% of the logical plan corresponding to $Q$, i.e., everything except $R_i$, 
% in order to materialize the query result. 
% Accurate distribution statistics of $Q(D)$ can then be used
% to better estimate the utility and latency of $R_i$, 
% which can be computed in a second phase.
% The downside, however, is that the optimizer may miss opportunities 
% to push down the $R_i$ operators inside the execution of $Q$. 
% A second method is to rely entirely on statistics on the base data,
% for both utility and latency computation, although
% estimation errors may affect the optimal choices for the discriminating view.
% A third method is a hybrid between the previous two,
% where some part of $Q$ is optimized and executed, and the intermediate 
% results materialized. 
% This can improve the accuracy of estimating the utility and latency metrics 
% while still maintaining the possibility of pushing down the $R_i$ operators. 
% Overall, there is an interesting space of possibilities that matches 
% previous works on query optimization for conventional queries\cite{DBLP:journals/ftdb/DeshpandeIR07}.


\vspace{-5pt}
\section{Enhancements and Extensions}\label{sec:extensions}

We now present some enhancements that may further improve the analyst's user experience beyond those suggested previously.



\stitle{Reducing Perceived Latency:}
	To reduce perceived latency, \SeeDB\ can first produce the discriminating view result in the top-K that takes the least amount of time to execute. That way, the user can peruse the first visualization as soon as possible. Then, \SeeDB\ can generate the remaining views. Further, \SeeDB\ can, in the background, compute the result of the current top-$K$ views while considering other views. If a view is no longer in the current top-K, then it is replaced with another (better) view, which begins executing.
	

\stitle{Latency Threshold:}
	 We may wish to incorporate a user-specified overall latency threshold in our goal (i.e., find top-$K$views such that total latency is bounded), so that the analyst does not have to wait too long to see visualizations. 
   Dealing with a latency threshold is certainly more challenging, and will require new techniques. One simple heuristic is to discard any views (without computation) whose cost is estimated to be large. Also, we may be able to leverage inter-dependencies between views for further pruning based on cost.
   \techreport{If we are computing discriminating views individually, the latency of discriminating views with the same group-by attribute is likely to be similar. Thus, as soon as we evaluate the latency of the best physical query plan for one discriminating view, we can immediately infer the latency of the best physical query plan for all discriminating views with the same group-by attribute.}
	

		% Idea 2: If Utility can be computed faster than Latency, can compute Utility first, then compute Latency, and other way around.


\stitle{General Settings:} 
  \SeeDB\ can be generalized to handle more elaborate discriminating views with little or no change. For instance, \SeeDB\ can easily handle multiple group-by attributes, resulting in multi-column views that can be visualized as stacked bar-charts.  Our discriminating views could include additional selection predicates (in addition to a group-by and an aggregation); for instance, in our staplers example, perhaps the trend line of total sales of staplers in California is an interesting visualization, because it differs from the total sales of staplers in the rest of the country. Overall, there is a rich space of general discriminating views we can consider.

\stitle{Refinement of Visualizations:} 
   \techreport{Since analysts are rarely interested in exact values in their visualizations, and are typically more interested in trends and comparisons, approximate visualizations may be just as useful to users as precise visualizations, but would be much more efficient to generate. In particular, we may be able to leverage ideas from online aggregation~\cite{DBLP:conf/sigmod/HellersteinHW97} to generate visualizations that improve (or become more accurate) over time.}
   \papertext{Since analysts are rarely interested in absolute values in their visualizations, we may be able to leverage ideas similar to those used in online aggregation~\cite{DBLP:conf/sigmod/HellersteinHW97} to produce visualizations that become more accurate over time.}

    % Producing Guarantees on Relationships between Outputs or Trends rather than Absolute Values


\stitle{Selecting Diverse Views:}
Our goal simply selects the K views with the highest utility, ignoring the fact that the discriminating views are related. For instance, an analyst may prefer one visualization each of sales and revenue, instead of two visualizations of sales, since the former covers more measure attributes. Incorporating such personalized preferences requires new models of discriminating view-diversity (leveraging metrics from recommendation systems) and hence new computation methods. 



\vspace{-3pt}
\section{Related Work}\label{sec:related}
\noindent Previous work related to \SeeDB\ falls under three themes: visualization tools (covered in Section 1), OLAP, and database visualizations:

\techreport{\stitle{Visualization Tools:} The visualization community has developed several tools for
data analysts. Tools like ShowMe~\cite{DBLP:journals/cacm/StolteTH08} and Polaris~\cite{DBLP:journals/tvcg/MackinlayHS07} (which formed the basis of the company Tableau) provide a canvas for users to drag and drop columns in order to browse visualizations. The visualizations considered are quite powerful --- including bar charts, pie charts, graphs, and many more. 

The work on Wrangler~\cite{DBLP:conf/chi/KandelPHH11} allowed users to transform a noisy dataset into a clean one, by automatic inference of schema information along with suggestions for deleting rows and pivoting columns. 

The work most closely related to ours in this space is the Profiler anomaly browser~\cite{DBLP:conf/avi/KandelPPHH12}, which enables data analysts to browse anomalies in data. The analyst specifies an anomaly, and the tool uses mutual information as a metric for picking the column to visualize that best explains an anomaly. On the other hand, our goal is to layer visualization over regular data base query processing; we support a broader class of queries and a broader class of visualizations. Furthermore, our focus is on efficiency of generation of these visualizations, which wasn't considered in that work.}

\stitle{OLAP:} There has been some work on browsing data cubes, allowing analysts to variously find ``explanations'' for why two cube values were different, to find which neighboring cubes have similar properties to the cube under consideration, or get suggestions on what unexplored data cubes should be looked at next~\cite{DBLP:conf/vldb/Sarawagi99, DBLP:conf/vldb/SatheS01, DBLP:conf/vldb/Sarawagi00}. \techreport{The work by Dash et al.~\cite{DBLP:conf/cikm/DashRMAL08} addresses similar problems in the faceted search scenario.}

\techreport{The OLAP papers are similar in spirit to our work of providing assistance to the data analyst, but approach it in
very different ways: The papers~\cite{DBLP:conf/vldb/Sarawagi99,DBLP:conf/vldb/SatheS01} both facilitate explanation-driven analysis --- the analyst specifies the anomaly, and the system provides explanations or generalizations for that anomaly. On the other hand, the paper~\cite{DBLP:conf/vldb/Sarawagi00} guides analysts to unexplored data cubes based on what has been seen so far. Our work is perhaps more similar to this paper. Unlike the approach described, which simply identifies {\em one} aggregate value, we instead focus on deviating {\em trends}, i.e., many aggregate values (which are then presented as visualizations), since it may be hard for the analyst to make sense of single absolute values. Additionally, they focus on star schemas, with one aggregation function on one measure attribute, while we intend to support queries on general databases, with an arbitrary number of aggregation functions.
}

\stitle{Database Visualization Work:} Fusion tables~\cite{DBLP:conf/sigmod/GonzalezHJLMSSG10} allows users to create visualizations layered on top of web databases; they do not consider the problem of automatic visualization generation. Devise~\cite{DBLP:conf/sigmod/LivnyRBCDLMW97} translated user-manipulated visualizations into database queries.  