\section{Introduction}
\label{sec:intro}
Data scientists analyze large amounts of data to find interesting trends and
gain novel insights. Given the large scale of data and relative ease of visual
analysis, analysts often use visualizations as a means to identify properties of
interest. The general analysis workflow is usually ad-hoc and can be represented
as follows: (1) The analyst selects a subset of the data they are interested
in; for instance, in a medical use-case (Section
\ref{subsec:motivation_example}), the analysts may select patients that had
expenses more than twice the standard deviation of all patients or patients
with a certain kind of disease. (2) Next, the analyst processes the data in
various ways, e.g. via binning, aggregates, group-bys etc. to generate a large
number of ``views'' of the data and builds visualizations such as scatterplots,
histograms, pie charts etc. for each view of the data. (3) The analyst then
studies all the views and identifies the {\it interesting} ones. (4) Once he/she
has identified the interesting views, he/she then drills down into these views
or further explores the properties that show unusual trends. This can be done
using sophisticated statistics or machine learning.

Of the four steps in the above process, only two (Steps 1 and 4) require
creative thinking and analyst input. Steps 2 and 3 are tedious and
time-consuming and ideal candidates for automation. Specifically, given the data that the analyst
is interested in (result of Step 1), we can automatically generate various
views of that data, evaluate each one for ``interesting''-ness and only surface
the most promising views. \SeeDB\ automates these labor-intensive parts of data
analysis.

\subsection{Motivating Example}
\label{subsec:motivation_example}

Consider a medical researcher studying the cost of care for cancer patients. Her
research involves the analysis of a set of 1M electronic medical records (EMRs).
To analyze this data, the researcher identifies patients that cost
significantly more than the average: specifically, she selects patients whose
cost of care is greater than the average cost by two standard deviations. In
terms of SQL, she runs the following query: \\

\noindent 
\begin{small}
\begin{verbatim}
Q = SELECT * FROM Patients where total_cost - 
(SELECT AVG(total_cost) from Patients) as avg_cost
> 2 * (SELECT STDDEV(total_cost) from Patients);
\end{verbatim}
\end{small}

Once she has identified these patients, she must study various aspects of their
care to determine the reason why the patients have large cost of care. For
instance, she may study length of treatment, survival rate, severity of disease
etc. For each of these parameters, she is interested in determining how the
group of patients with high cost of care are different from the overall group of
patients. As a result, she may construct various views of the data that
compare various metrics between the high cost patients and the overall patient
population. For instance, she may compare the distribution of length of
treatment for the two populations, the average severity of the disease
etc. Since there are a large number of metrics that may be responsible for high
cost of care, the analyst must construct, visualize and examine a large number
of views to identify interesting trends. For more than 5 metrics, this process
quickly becomes tedious and time-consuming. We can significantly simplify and
speed up the analysis process if we can automate the creation and evaluation of
views.

In this demo, we propose to demonstrate a system called \SeeDB\
\cite{DBLP:conf/vldb/Parameswaran2013} that partially automates the data
analysis process. Given a query posed by the researcher, \SeeDB\ can compute a
large number of views based on that query, determine the ``interesting''-ness or
utility of each of the view and show to the user only those views that it deems
most interesting. The researcher can then focus only on the important trends in
the data.

Since \SeeDB\ must rank views based on utility, accurately measuring
``interesting"-ness or utility is cruicial. \SeeDB\ is based on the principle
that it is the {\bf deviations from expected behavior that make a view
interesting}. For instance, in the above example, the researcher would be
interested in the fact that high-cost patients actually visit a specific set of
doctors compared to the entire patient population. Similarly, the researcher
would be interested in knowing that the high-cost patients have longer hospital
stays compared to the rest of the population. Thus, given a query, interesting
trends are those that differ significantly between the query and the underlying
dataset. \SeeDB\ therefore assigns higher utility to views that show divergent
trends. (Since it may be more appropriate to compare the high-cost patients with
other patients having the same disease but lower cost, so \SeeDB\ allows the
user to specify what dataset to compare with).

In the process of automatically producing an interesting set of views for any
query, \SeeDB\ must address a few challenges: (a) the size of
the space of potential views increases exponentially with the number of
attributes in a table, as a result, \SeeDB\ must intelligently explore this
space; (b) computing each view and its utility independently is expensive and
wasteful, and hence \SeeDB\ must share computation between queries; and (c)
since visual analysis must happen in real-time, \SeeDB\ must tradeoff accuracy
of views for reduced latency. In Section \ref{sec:system_architecture}, we
describe how \SeeDB\ addresses these challenges.

\subsection{State-of-the-Art Approaches}
\label{related_work}

Over the past few years, there has been a significant
effort from the visualization community to provide interactive tools
for data analysts. In particular, tools such as ShowMe, Polaris, and
Tableau~\cite{DBLP:journals/cacm/StolteTH08,
  DBLP:journals/tvcg/MackinlayHS07} provide a canvas for data analysts
to manipulate and view data, tools such as
Wrangler~\cite{DBLP:conf/chi/KandelPHH11} allow data analysts to
transform and clean data, and tools such as
Profiler~\cite{DBLP:conf/avi/KandelPPHH12} allow users to visualize
simple anomalies in data.  However, unlike \SeeDB, these tools have
little automation; in effect, it is up to the analyst to generate a
two-column view to be visualized. Other related areas of work include OLAP and
database visualization tools. There has been some work on browsing data cubes, allowing
analysts to variously find ``explanations'' for why two cube values were
different, to find which neighboring cubes have similar properties to the cube
under consideration, or get suggestions on what unexplored data cubes should be
looked at next~\cite{DBLP:conf/vldb/Sarawagi99, DBLP:conf/vldb/SatheS01,
DBLP:conf/vldb/Sarawagi00}.

Fusion tables~\cite{DBLP:conf/sigmod/GonzalezHJLMSSG10} allows users to create
visualizations layered on top of web databases; they do not consider the problem
of automatic visualization generation.
Devise~\cite{DBLP:conf/sigmod/LivnyRBCDLMW97} translated user-manipulated
visualizations into database queries.


% \noindent There are several technical challenges that need to be addressed:
% 
% \begin{denselist}
% 
% \item For a given query, $n$, the total number of discriminating views, (even if
% we restrict ourselves to views that append a group-by and an aggregation) is
% likely to be very large to explore exhaustively and precisely. Generating each
% of $R_1(Q(D)),$  $\ldots,$ $R_n(Q(D))$, scoring them on utility, and then
% picking the best one is certainly not feasible for most databases. Thus, we need
% mechanisms to prune the space of views and compute their utility approximately.
% 
% \item Generating and scoring the discriminating views $R_i(Q(D))$ one-by-one may
% miss interesting optimization opportunities: First, we may share computation
% between discriminating views.  For example, the results of two views with
% different aggregates but the same group-by may be computed together in one
% query, followed by projecting out to reveal the two individual views.  Second,
% by evaluating the discriminating views in a deliberate order, we may be able to
% prune views with low utility (without evaluation) that are definitely not going
% to be recommended to the analyst.
% 
% \item Since visualizations tend to convey approximate information, e.g., a trend
% in a line plot may be more important than knowing the exact coordinates of each
% point, we can introduce approximations as part of \SeeDB.  Thus, the utility of
% a discriminating view may be computed approximately but efficiently, and the
% recommended discriminating views can be populated with approximate results,
% based on synopses of the base data or of the query result, that can be generated
% much more efficiently.
% 
% \end{denselist}
