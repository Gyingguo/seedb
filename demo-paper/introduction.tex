\section{Introduction}
\label{sec:intro}

% Data scientists analyzing large amounts of data often rely on visualizations to
% identify interesting trends and gain insights. However, picking the right
% visualization is a manual and tedious task. Given a query, the analyst would
% like to know what makes the results of a query ``interesting'' compared to the
% underlying dataset. In this paper, we demonstrate a prototype of a system
% \SeeDB\ , a system that automatically discovers statistical differences between
% the query results and the underlying dataset, and visualizes the differences to
% aid data exploration.

Data scientists analyze large amounts of data to find new insights, trends and
anomalies. Given the large amount of data and large bandwidth available for
visual analysis, analysts often use visualizations to identify areas of
interest. The general workflow, which is usually ad-hoc, can be represented as
follows:

\begin{enumerate}
  \item Step 1: Analyst selects a subset of the data they are interested in; for
  instance, the analysts may select patients that had costs more than twice the
  standard deviation of all patients, or the genes that belong to a particular
  group, or a set of products of a certain kind.
  \item Step 2: The analyst processes and visualizes the data in various ways,
  e.g. via binning, aggregates, group-bys etc. and then building scatterplots,
  histograms etc., and studies these ``views'' of the data.
  \item Step 3: Finally, the analyst studies all the views and identifies the
  interesting ones. He/she then drills down into these views or further explores
  the properties that show unusual trends. This can be done using sophisticated
  statistics or machine learning.
\end{enumerate}

This iterative process and repeated for different subsets of the data. Since a
large number of views of the data are possible, this process of exploration is
tedious and time-consuming. In Step 3 above, we further posit that {\it what
makes a view interesting is deviations from expected behavior}. Therefore, given
the subset of data selected using a relational query, what makes the data
interesting are trends or properties that are different for this subset compared
to the underlying complete dataset.

Ultimately, the analyst must decide if deviations in the data are interesting
but we can use deviation as a means to eliminate the laborious process
of stepping through all possible views of a dataset. 

<<<Example>>>

In this demo paper, we describe our prototype of \SeeDB, a system to
automatically identify and visually highlight interesting aspects of a dataset. 

While various ways of obtaining ``views'' of a dataset are possible, for the
purpose of this work, we focus on views obtained by adding a single group-by and
a single aggregate clause to the query used to select subsets of the data. This
restriction also allows us to focus on a limited set of visualization types to
show trends in the data.

Formally, the problem can be described as follows: given a database and a query
$Q$, \SeeDB identifies the most significant deviations between the subset of the
data selected by the query and the underlying dataset. \SeeDB does so by
considering the space of views obtained by adding a single group-by and
aggregate to the input query, and then computing the discriminating power of
each of these views. Discriminating power or utility measures how different the
distribution of data in the subset is compared to the underlying data. \SeeDB
produces the top-k views having the highest dicriminating power. For the utility
measure, \SeeDB provides the option of using distance metrics such as earth
movers distance, L2 norm etc.

\begin{example}\label{example}
\vspace{-10pt}
We focus on a database with a traditional star sch\-ema.
We operate on a single fact table $D$, containing information
about sales. The schema of $D$ comprises three dimension
attributes: \att{Product}, \att{Location}, and \att{Year}, and
one measure attribute: \att{Sales}.

Let us assume our analyst has entered a query with a
single selection predicate:
$Q \equiv \sigma_{(\att{Product = Staplers})}$.
The result contains too many tuples to examine individually, and
hence the analyst has to rely on some appropriate visualization in order
to glean interesting insights about the overall query result.

\SeeDB\ searches over all possible discriminating views that
can be obtained by adding a single aggregate and group by operator.
We initially focus on these two-attribute discriminating views
because they are easy to visualize using histograms or line plots.
(\SeeDB\ also considers more general views.)
One of these queries is 
$Q_1' = R_1(Q)$ where $R_1 \equiv \gamma_{\att{Location, sum(Sales)}}$.
This query tracks the sum of \att{Sales} over \att{Location}.
A possible result, $R_1(Q(D))$, is the discriminating view
shown in the top part of Table 2.
Another possible query is $Q_2' = R_2(Q)$, where $R_2 \equiv
\gamma_{\att{Year, sum(Sales)}}$, tracking the sum of
\att{Sales} over \att{Year}.
The bottom part of Table 2 shows a possible result of this
second view.


The next step is to score each view based on its utility, i.e., its
ability to show an interesting property of the query result. For this
purpose, \SeeDB\ obtains aggregate statistics for
\att{Sales} for \att{Location} and \att{Year} for the original full database.
(As we will see later, there
are interesting optimization opportunities if we can integrate this
step with the processing of $Q$.)
Table 1 shows the full database aggregates, i.e., $R_1(D)$ and $R_2(D)$
corresponding to our sample views.
(Note the missing $Q$.)
For the \att{Location} attribute, both $R_1(D)$ and $R_1(Q(D))$
have similar distributions.
(The fact that sales are uniformly lower in $R_1(Q(D))$ is not
surprising since $R_1(Q(D))$ only considers a fraction of the data.)
However, notice that the
distribution across \att{Year}s is very different for tuples
satisfying \att{Product = `Staplers'}. That is, demand for
\att{`Staplers'} seems to have not gone up, unlike the other products.
This unexpected behavior will be detected by \SeeDB\ when it
computes the utility of $R_2(Q)$, and hence $R_2(Q)$
(and not $R_1(Q)$) will be suggested to the analyst for further human evaluation.

\vspace{-10pt}
\end{example}


\begin{table}
{\scriptsize \center
\vspace{-10pt}
\begin{tabular}{|c|c|c|c|}
\hline
\multicolumn{4}{|c|}{\att{Location} Aggregates: $R_1(Q(D))$ } \\ \hline
Boston: 30 & Seattle: 40 & New York: 40
& San Francisco: 90  \\
\hline
 \hline 
\multicolumn{4}{|c|}{\att{Year} Aggregates: $R_2(Q(D))$} \\ \hline
2009: 50 & 2010: 40 & 2011: 60 & 2012: 50  \\
\hline
\end{tabular} 

\vspace{-10pt}
\caption{Aggregates for \att{Product = `Staplers'} \label{tab:new-agg}}
}
\end{table}


\begin{table}
\vspace{-10pt}
{\scriptsize \center

\begin{tabular}{|c|c|c|c|}
\hline
\multicolumn{4}{|c|}{\att{Location} Aggregates: $R_1(D)$} \\ \hline
Boston: 300 & Seattle: 300 & New York: 300
& San Francisco: 700  \\
\hline
 \hline 
\multicolumn{4}{|c|}{\att{Year} Aggregates: $R_2(D)$ } \\ \hline
2009: 100 & 2010: 200 & 2011: 500 & 2012: 800  \\
\hline
\end{tabular} 

\vspace{-10pt}
\caption{Original Aggregates\label{tab:original-agg}}
}
\vspace{-18pt}
\end{table}

\noindent Thus, there are several technical challenges that need to be addressed:

\begin{denselist}

\item For a given query, $n$, the total number of discriminating views, (even if
we restrict ourselves to views that append a group-by and an aggregation) is
likely to be very large to explore exhaustively and precisely. Generating each
of $R_1(Q(D)),$  $\ldots,$ $R_n(Q(D))$, scoring them on utility, and then
picking the best one is certainly not feasible for most databases. Thus, we need
mechanisms to prune the space of views and compute their utility approximately.

\item Generating and scoring the discriminating views $R_i(Q(D))$ one-by-one may
miss interesting optimization opportunities: First, we may share computation
between discriminating views.  For example, the results of two views with
different aggregates but the same group-by may be computed together in one
query, followed by projecting out to reveal the two individual views.  Second,
by evaluating the discriminating views in a deliberate order, we may be able to
prune views with low utility (without evaluation) that are definitely not going
to be recommended to the analyst.

\item Since visualizations tend to convey approximate information, e.g., a trend
in a line plot may be more important than knowing the exact coordinates of each
point, we can introduce approximations as part of \SeeDB.  Thus, the utility of
a discriminating view may be computed approximately but efficiently, and the
recommended discriminating views can be populated with approximate results,
based on synopses of the base data or of the query result, that can be generated
much more efficiently.

\end{denselist}

Over the past few years, there has been a significant
effort from the visualization community to provide interactive tools
for data analysts. In particular, tools such as ShowMe, Polaris, and
Tableau~\cite{DBLP:journals/cacm/StolteTH08,
  DBLP:journals/tvcg/MackinlayHS07} provide a canvas for data analysts
to manipulate and view data, tools such as
Wrangler~\cite{DBLP:conf/chi/KandelPHH11} allow data analysts to
transform and clean data, and tools such as
Profiler~\cite{DBLP:conf/avi/KandelPPHH12} allow users to visualize
simple anomalies in data.  However, unlike \SeeDB, these tools have
little automation; in effect, it is up to the analyst to generate a
two-column result (like the result of the discriminating view)
to be visualized. Other related areas of work include OLAP and database
visualization tools. There has been some work on browsing data cubes, allowing
analysts to variously find ``explanations'' for why two cube values were
different, to find which neighboring cubes have similar properties to the cube
under consideration, or get suggestions on what unexplored data cubes should be
looked at next~\cite{DBLP:conf/vldb/Sarawagi99, DBLP:conf/vldb/SatheS01,
DBLP:conf/vldb/Sarawagi00}.

Fusion tables~\cite{DBLP:conf/sigmod/GonzalezHJLMSSG10} allows users to create
visualizations layered on top of web databases; they do not consider the problem
of automatic visualization generation.
Devise~\cite{DBLP:conf/sigmod/LivnyRBCDLMW97} translated user-manipulated
visualizations into database queries.